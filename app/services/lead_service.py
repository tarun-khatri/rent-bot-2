"""
AI-powered lead management service with strict flow control.
All responses are generated by AI with stage-specific prompts and business rules.
"""

import logging
import os
import re
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Tuple
from flask import current_app
from app.services.database_service import db_service
from app.services.gemini_service import gemini_service
from app.config import get_current_time

logger = logging.getLogger(__name__)


class LeadService:
    """AI-powered service for managing lead qualification and conversation flows"""
    
    def __init__(self):
        """Initialize the lead service"""
        self.greeting_patterns = [
            r'\b(×©×œ×•×|×”×™×™|×”×œ×•|hello|hi|hey)\b',
            r'\b(×‘×•×§×¨ ×˜×•×‘|×¢×¨×‘ ×˜×•×‘|×œ×™×œ×” ×˜×•×‘)\b',
            r'\b(××™×š ×”×•×œ×š|××” × ×©××¢|××” ×§×•×¨×”)\b'
        ]
    
    def process_lead_message(self, phone_number: str, name: str, message: str) -> str:
        """Main entry point for processing lead messages with AI responses"""
        try:
            logger.info(f"Processing message from {name} ({phone_number}): {message[:50]}...")
            
            # Get or create lead
            lead = db_service.get_lead_by_phone(phone_number)
            if not lead:
                lead = db_service.create_lead(phone_number, name)
                logger.info(f"New lead created: {lead['id']}")
            
            # Log user message
            db_service.log_conversation(lead['id'], 'user', message)
            
            # Check for greeting to restart conversation flow
            if self._is_greeting(message) and lead.get('stage') not in ['new', 'qualified', 'tour_scheduled']:
                logger.info(f"Detected greeting from lead {lead['id']}, restarting conversation")
                db_service.update_lead(lead['id'], {'stage': 'new'})
                lead = db_service.get_lead_by_phone(phone_number)  # Refresh lead data
            
            # Process based on current stage with AI
            response = self._process_by_stage_with_ai(lead, message)
            
            # Log bot response
            db_service.log_conversation(lead['id'], 'bot', response)
            
            logger.info(f"AI response generated for lead {lead['id']}, length: {len(response)}")
            return response
            
        except Exception as e:
            logger.error(f"Error processing lead message: {e}")
            return "××¦×˜×¢×¨, ×™×© ×œ×™ ×‘×¢×™×” ×˜×›× ×™×ª. ×× × × ×¡×” ×©×•×‘ ×‘×¢×•×“ ×›××” ×“×§×•×ª."
    
    def _process_by_stage_with_ai(self, lead: Dict, message: str) -> str:
        """Process message using AI with stage-specific flow control and edge case handling"""
        stage = lead.get('stage', 'new')
        
        logger.info(f"Processing AI response for lead {lead['id']} in stage: {stage}")
        
        # Get conversation history for context
        conversation_history = db_service.get_conversation_history(lead['id'], limit=15)
        
        # EDGE CASE HANDLING: Check for qualification restart requests
        restart_result = self._check_for_qualification_restart(lead, message, conversation_history)
        logger.info(f"Restart check result for lead {lead['id']}: {restart_result is not None}")
        if restart_result:
            logger.info(f"Returning restart result for lead {lead['id']}")
            return restart_result
        
        # Handle stage transitions and business logic
        if stage == 'new':
            return self._handle_new_lead_with_ai(lead, message, conversation_history)
        elif stage == 'gate_question_payslips':
            return self._handle_payslips_with_ai(lead, message, conversation_history)
        elif stage == 'gate_question_deposit':
            return self._handle_deposit_with_ai(lead, message, conversation_history)
        elif stage == 'gate_question_move_date':
            return self._handle_move_date_with_ai(lead, message, conversation_history)
        elif stage == 'collecting_profile':
            return self._handle_profile_collection_with_ai(lead, message, conversation_history)
        elif stage == 'qualified':
            return self._handle_qualified_lead_with_ai(lead, message, conversation_history)
        elif stage == 'scheduling_in_progress':
            return self._handle_scheduling_in_progress_with_ai(lead, message, conversation_history)
        elif stage == 'tour_scheduled':
            return self._handle_tour_scheduled_with_ai(lead, message, conversation_history)
        elif stage in ['gate_failed', 'no_fit', 'future_fit']:
            return self._handle_ended_conversation_with_ai(lead, message, conversation_history)
        else:
            logger.warning(f"Unknown stage for lead {lead['id']}: {stage}")
            return self._handle_unknown_stage_with_ai(lead, message, conversation_history)
    
    def _check_for_qualification_restart(self, lead: Dict, message: str, conversation_history: List[Dict]) -> Optional[str]:
        """
        COMPREHENSIVE EDGE CASE HANDLER
        Checks if user wants to restart qualification process or change previous answers
        """
        stage = lead['stage']
        message_lower = message.lower().strip()
        
        # Edge Case 1: User in failed/ended stage but provides qualification info
        if stage in ['gate_failed', 'no_fit', 'future_fit']:
            logger.info(f"Lead {lead['id']} in failed stage, checking message: '{message_lower}'")
            
            # Check for deposit mentions FIRST (more specific)
            deposit_keywords = ['deposit', 'guarantee', 'month', '×¢×¨×‘×•×ª', '×—×•×“×©', 'pay', 'afford', 'can pay', '××©×œ×', '×™×›×•×œ ×œ×©×œ×']
            found_deposit_keyword = next((kw for kw in deposit_keywords if kw in message_lower), None)
            
            if found_deposit_keyword:
                logger.info(f"Lead {lead['id']} providing deposit info after failed stage - found keyword: '{found_deposit_keyword}'")
                return self._handle_post_failure_deposit_claim(lead, message, conversation_history)
            
            # Check for payslips mentions (but NOT if it's about deposit)
            if any(keyword in message_lower for keyword in ['payslip', 'salary', 'income', '×ª×œ×•×©']) and not any(dep_word in message_lower for dep_word in ['deposit', 'guarantee', '×¢×¨×‘×•×ª']):
                logger.info(f"Lead {lead['id']} providing payslips info after gate_failed - restarting qualification")
                return self._restart_payslips_qualification(lead, message, conversation_history)
            
            # Check for move date changes - be more specific
            move_date_indicators = ['days', 'week', 'soon', 'immediately', '×™×•×', '×©×‘×•×¢', '××™×“', '×‘×§×¨×•×‘']
            if (any(indicator in message_lower for indicator in move_date_indicators) and 
                not is_about_deposit and
                len(message_lower) > 5):  # Avoid single word responses
                logger.info(f"Lead {lead['id']} providing new move date after failed stage")
                return self._handle_post_failure_move_date(lead, message, conversation_history)
        
        # Edge Case 2: User wants to restart entire process
        restart_phrases = ['restart', 'start over', 'begin again', '××—×“×©', '×©×•×‘', '××”×ª×—×œ×”']
        if any(phrase in message_lower for phrase in restart_phrases):
            logger.info(f"Lead {lead['id']} explicitly requesting process restart")
            return self._restart_entire_qualification(lead, conversation_history)
        
        # Edge Case 3: User contradicts previous answer in same conversation - BUT be more lenient
        if stage in ['gate_question_payslips', 'gate_question_deposit', 'gate_question_move_date']:
            contradiction_result = self._check_for_contradictions(lead, message, conversation_history)
            if contradiction_result:
                return contradiction_result
        
        # Edge Case 4: User asking questions instead of answering - handle gracefully
        if self._is_asking_question(message) and stage.startswith('gate_question'):
            logger.info(f"Lead {lead['id']} asking question instead of answering in {stage}")
            return self._handle_user_question(lead, message, conversation_history)
        
        # Edge Case 5: User providing irrelevant information - be less strict
        if self._is_clearly_off_topic(message, stage):
            logger.info(f"Lead {lead['id']} clearly off-topic in stage {stage}")
            return self._redirect_to_current_question(lead, conversation_history)
        
        return None
    
    def _restart_payslips_qualification(self, lead: Dict, message: str, conversation_history: List[Dict]) -> str:
        """Restart qualification when user claims to have payslips after saying no"""
        logger.info(f"Restarting payslips qualification for lead {lead['id']}")
        
        # Analyze the new payslips claim
        yes_no_response = self._analyze_yes_no_response(message, context='payslips')
        
        if yes_no_response == 'yes':
            # User now claims to have payslips - restart the process
            db_service.update_lead(lead['id'], {
                'stage': 'gate_question_deposit',
                'has_payslips': True
            })
            updated_lead = db_service.get_lead_by_phone(lead['phone_number'])
            return gemini_service.generate_stage_response('gate_question_deposit', updated_lead, conversation_history, message)
        else:
            # Still unclear - ask for clarification
            return gemini_service.generate_stage_response(lead['stage'], lead, conversation_history, message)
    
    def _handle_post_failure_deposit_claim(self, lead: Dict, message: str, conversation_history: List[Dict]) -> str:
        """Handle deposit claims after failed qualification with better understanding"""
        logger.info(f"Handling post-failure deposit claim for lead {lead['id']}")
        logger.info(f"Lead status - payslips: {lead.get('has_payslips')}, deposit: {lead.get('can_pay_deposit')}")
        
        # If they already failed on payslips, we need payslips first
        if lead.get('has_payslips') == False:
            logger.info(f"Lead {lead['id']} failed payslips, asking for payslips first")
            return gemini_service.generate_stage_response('gate_failed', lead, conversation_history, 
                "×¢×“×™×™×Ÿ ×¦×¨×™×š ×’× ×ª×œ×•×©×™ ×©×›×¨. ×™×© ×œ×š ×ª×œ×•×©×™ ×©×›×¨ ××”×—×•×“×©×™×™× ×”××—×¨×•× ×™×?")
        
        # Enhanced deposit claim analysis with context
        yes_no_response = self._analyze_yes_no_response(message, context='deposit')
        logger.info(f"Deposit claim analysis for lead {lead['id']}: '{message}' -> '{yes_no_response}'")
        
        # More liberal acceptance of deposit agreement
        if (yes_no_response == 'yes' or 
            any(phrase in message.lower() for phrase in [
                'ok', '××•×§×™×™', '×‘×¡×“×¨', '×˜×•×‘', 'ill pay', '××©×œ×', '×™×›×•×œ ×œ×©×œ×', 
                'can pay', '××ª×Ÿ', '× ×ª×Ÿ', 'provide', '××¡×¤×§'
            ])):
            logger.info(f"Lead {lead['id']} agreed to pay deposit - restarting qualification")
            db_service.update_lead(lead['id'], {
                'stage': 'gate_question_move_date',
                'can_pay_deposit': True
            })
            updated_lead = db_service.get_lead_by_phone(lead['phone_number'])
            return gemini_service.generate_stage_response('gate_question_move_date', updated_lead, conversation_history, message)
        
        # If clearly negative
        if yes_no_response == 'no':
            logger.info(f"Lead {lead['id']} clearly cannot pay deposit - staying failed")
            return gemini_service.generate_stage_response('gate_failed', lead, conversation_history, message)
        
        # If unclear, ask for clarification with empathy
        logger.info(f"Lead {lead['id']} deposit response unclear - asking for clarification")
        clarification_prompt = f"×œ× ×œ×’××¨×™ ×”×‘× ×ª×™. ×”×× ×™×© ×œ×š ×™×›×•×œ×ª ×œ×”×¤×§×™×“ ×¢×¨×‘×•×ª ×©×œ 2 ×—×•×“×©×™ ×©×›×™×¨×•×ª? (×›×Ÿ/×œ×)"
        return gemini_service.generate_stage_response('gate_failed', lead, conversation_history, clarification_prompt)
    
    def _handle_post_failure_move_date(self, lead: Dict, message: str, conversation_history: List[Dict]) -> str:
        """Handle move date changes after failed qualification"""
        logger.info(f"Handling post-failure move date for lead {lead['id']}")
        
        # Check if they passed other gate questions first
        if not lead.get('has_payslips') or not lead.get('can_pay_deposit'):
            return gemini_service.generate_stage_response('gate_failed', lead, conversation_history, 
                "×¢×“×™×™×Ÿ ×¦×¨×™×š ×œ×¢×‘×•×¨ ××ª ×›×œ ×‘×“×™×§×•×ª ×”×›×©×¨×•×ª ×§×•×“×.")
        
        # Evaluate new move date
        days_until_move = self._extract_move_in_days(message)
        max_days = current_app.config.get('MAX_MOVE_IN_DAYS', 60)
        
        if days_until_move <= max_days:
            db_service.update_lead(lead['id'], {
                'stage': 'collecting_profile',
                'move_in_date': message.strip()
            })
            updated_lead = db_service.get_lead_by_phone(lead['phone_number'])
            return gemini_service.generate_stage_response('collecting_profile', updated_lead, conversation_history, message)
        
        return gemini_service.generate_stage_response('future_fit', lead, conversation_history, message)
    
    def _restart_entire_qualification(self, lead: Dict, conversation_history: List[Dict]) -> str:
        """Restart the entire qualification process"""
        logger.info(f"Restarting entire qualification for lead {lead['id']}")
        
        # Reset lead to initial state
        db_service.update_lead(lead['id'], {
            'stage': 'gate_question_payslips',
            'has_payslips': None,
            'can_pay_deposit': None,
            'move_in_date': None,
            'rooms': None,
            'budget': None,
            'has_parking': None,
            'preferred_area': None
        })
        
        updated_lead = db_service.get_lead_by_phone(lead['phone_number'])
        return gemini_service.generate_stage_response('gate_question_payslips', updated_lead, conversation_history, "××ª×—×™×œ×™× ××—×“×©")
    
    def _check_for_contradictions(self, lead: Dict, message: str, conversation_history: List[Dict]) -> Optional[str]:
        """Check if current message contradicts previous answers - but only for SAME question type"""
        stage = lead['stage']
        message_lower = message.lower().strip()
        
        # Only check for contradictions in active qualification stages
        if stage not in ['gate_question_payslips', 'gate_question_deposit', 'gate_question_move_date']:
            return None
        
        # Get context for current stage
        current_context = {
            'gate_question_payslips': 'payslips',
            'gate_question_deposit': 'deposit', 
            'gate_question_move_date': 'move_date'
        }.get(stage)
        
        # Check conversation history for previous answers to THE SAME QUESTION TYPE
        try:
            # Only look at the last 2-3 user messages to avoid false positives
            recent_user_messages = [conv for conv in conversation_history[-6:] if conv.get('message_type') == 'user'][-2:]
            
            for conv in reversed(recent_user_messages):
                previous_content = conv.get('content', '').lower()
                
                # Only check contradiction if discussing same topic
                is_same_topic = False
                if current_context == 'payslips' and any(word in previous_content for word in ['×ª×œ×•×©', 'salary', 'payslip']):
                    is_same_topic = True
                elif current_context == 'deposit' and any(word in previous_content for word in ['×¢×¨×‘×•×ª', 'deposit', 'guarantee', 'pay', '×©×œ×']):
                    is_same_topic = True
                elif current_context == 'move_date' and any(word in previous_content for word in ['×™×•×', 'day', 'week', '×©×‘×•×¢', '×—×•×“×©']):
                    is_same_topic = True
                
                if is_same_topic:
                    previous_response = self._analyze_yes_no_response(previous_content, current_context)
                    current_response = self._analyze_yes_no_response(message, current_context)
                    
                    # Only flag as contradiction if CLEARLY opposite responses on SAME topic
                    if (previous_response in ['yes', 'no'] and current_response in ['yes', 'no'] and 
                        previous_response != current_response):
                        logger.info(f"Same-topic contradiction detected for lead {lead['id']}: {previous_response} vs {current_response} on {current_context}")
                        return self._handle_contradiction(lead, message, conversation_history, previous_response, current_response)
                    
        except Exception as e:
            logger.error(f"Error checking for contradictions for lead {lead['id']}: {e}")
            # Continue without contradiction checking if there's an error
        
        return None
    
    def _handle_contradiction(self, lead: Dict, message: str, conversation_history: List[Dict], 
                            previous: str, current: str) -> str:
        """Handle when user gives contradictory answers"""
        logger.info(f"Handling contradiction for lead {lead['id']}: {previous} -> {current}")
        
        # Use the most recent answer and acknowledge the change
        confirmation_message = f"×”×‘× ×ª×™ ×©×”×ª×©×•×‘×” ×©×œ×š ×”×©×ª× ×ª×” ×'{previous}' ×œ'{current}'. × ××©×™×š ×¢× ×”×ª×©×•×‘×” ×”×—×“×©×”."
        
        # Process the new answer based on current stage
        stage = lead['stage']
        if stage == 'gate_question_payslips':
            return self._handle_payslips_with_ai(lead, message, conversation_history)
        elif stage == 'gate_question_deposit':
            return self._handle_deposit_with_ai(lead, message, conversation_history)
        elif stage == 'gate_question_move_date':
            return self._handle_move_date_with_ai(lead, message, conversation_history)
        
        return gemini_service.generate_stage_response(stage, lead, conversation_history, message)
    
    def _is_asking_question(self, message: str) -> bool:
        """Check if user is asking a question instead of answering"""
        message_lower = message.lower().strip()
        
        # Don't treat area responses as questions  
        if any(area_indicator in message_lower for area_indicator in ['anywhere', 'any', '×›×œ', '×œ× ××©× ×”', '×‘×›×œ']):
            return False
            
        question_indicators = [
            '?', 'how much', 'what is', 'when can', 'where is', 'why', 'who',
            '××™×š', '××” ×–×”', '××ª×™ ××¤×©×¨', '××™×¤×” × ××¦×', '×œ××”', '××™', '×›××” ×¢×•×œ×”', '××—×™×¨'
        ]
        return any(indicator in message_lower for indicator in question_indicators)
    
    def _is_clearly_off_topic(self, message: str, stage: str) -> bool:
        """Check if message is CLEARLY off-topic for current stage - be more lenient"""
        message_lower = message.lower().strip()
        
        # During gate questions, only flag as off-topic if it's REALLY unrelated
        if stage.startswith('gate_question'):
            # Only flag as off-topic if discussing complex property details
            clearly_off_topic = [
                'floor plan', 'square meters', 'exact address', 'renovation', 'furniture', 
                '×ª×•×›× ×™×ª ×“×™×¨×”', '××˜×¨×™× ×¨×‘×•×¢×™×', '×›×ª×•×‘×ª ××“×•×™×§×ª', '×©×™×¤×•×¦×™×', '×¨×™×”×•×˜'
            ]
            # Don't flag basic questions about rooms/price as off-topic - they might be clarifying
            return any(keyword in message_lower for keyword in clearly_off_topic)
        
        return False
    
    def _handle_user_question(self, lead: Dict, message: str, conversation_history: List[Dict]) -> str:
        """Handle when user asks a question instead of answering"""
        stage = lead['stage']
        
        # Brief answer + redirect to current question
        if stage == 'gate_question_payslips':
            return gemini_service.generate_stage_response(stage, lead, conversation_history, 
                "××¢× ×” ×¢×œ ×–×” ×‘×”××©×š. ×§×•×“× ×›×œ, ×™×© ×œ×š ×ª×œ×•×©×™ ×©×›×¨ ××”×—×•×“×©×™×™× ×”××—×¨×•× ×™×?")
        elif stage == 'gate_question_deposit':
            return gemini_service.generate_stage_response(stage, lead, conversation_history, 
                "× ×“×‘×¨ ×¢×œ ×–×” ××—×¨ ×›×š. ×¢×›×©×™×• ×—×©×•×‘ ×œ×™ ×œ×“×¢×ª - ×™×© ×œ×š ×™×›×•×œ×ª ×œ×”×¤×§×™×“ ×¢×¨×‘×•×ª ×©×œ 2 ×—×•×“×©×™ ×©×›×™×¨×•×ª?")
        elif stage == 'gate_question_move_date':
            return gemini_service.generate_stage_response(stage, lead, conversation_history, 
                "××¢× ×” ×¢×œ ×–×” ×‘×¨×’×¢ ×©× ×¡×™×™×. ××ª×™ ××ª×” ××ª×›× ×Ÿ ×œ×”×™×›× ×¡ ×œ×“×™×¨×”?")
        else:
            return gemini_service.generate_stage_response(stage, lead, conversation_history, message)
    
    def _redirect_to_current_question(self, lead: Dict, conversation_history: List[Dict]) -> str:
        """Redirect user back to current stage question"""
        stage = lead['stage']
        
        if stage == 'gate_question_payslips':
            redirect_message = "×‘×•××• × ×ª××§×“ ×§×•×“× ×‘×‘×“×™×§×•×ª ×”×›×©×¨×•×ª. ×™×© ×œ×š ×ª×œ×•×©×™ ×©×›×¨ ××”×—×•×“×©×™×™× ×”××—×¨×•× ×™×?"
        elif stage == 'gate_question_deposit':
            redirect_message = "× ×“×‘×¨ ×¢×œ ×–×” ××—×¨ ×›×š. ×¢×›×©×™×• ×× ×™ ×¦×¨×™×š ×œ×“×¢×ª - ×™×© ×œ×š ×™×›×•×œ×ª ×œ×”×¤×§×™×“ ×¢×¨×‘×•×ª ×©×œ 2 ×—×•×“×©×™ ×©×›×™×¨×•×ª?"
        elif stage == 'gate_question_move_date':
            redirect_message = "××ª×™ ××ª×” ××ª×›× ×Ÿ ×œ×”×™×›× ×¡ ×œ×“×™×¨×”?"
        else:
            redirect_message = "×‘×•××• × ××©×™×š ×¢× ×”×ª×”×œ×™×š ×”×©×œ×‘ ××—×¨ ×©×œ×‘"
        
        return gemini_service.generate_stage_response(stage, lead, conversation_history, redirect_message)
    
    def _handle_new_lead_with_ai(self, lead: Dict, message: str, conversation_history: List[Dict]) -> str:
        """Handle new lead with AI-generated welcome and first gate question"""
        logger.info(f"Handling new lead {lead['id']} with AI")
        
        # Update stage to first gate question
        db_service.update_lead(lead['id'], {'stage': 'gate_question_payslips'})
        
        # Get AI response for new lead welcome
        return gemini_service.generate_stage_response('new', lead, conversation_history, message)
    
    def _handle_payslips_with_ai(self, lead: Dict, message: str, conversation_history: List[Dict]) -> str:
        """Handle payslips response with AI and business logic"""
        logger.info(f"Handling payslips response for lead {lead['id']} with AI")
        
        # Analyze response type with context
        response_type = self._analyze_yes_no_response(message, context='payslips')
        
        if response_type == 'no':
            # Failed gate question
            db_service.update_lead(lead['id'], {
                'stage': 'gate_failed',
                'has_payslips': False
            })
            return gemini_service.generate_stage_response('gate_failed', lead, conversation_history, message)
            
        elif response_type == 'yes':
            # Passed first gate, move to second question
            db_service.update_lead(lead['id'], {
                'stage': 'gate_question_deposit',
                'has_payslips': True
            })
            # Refresh lead data for updated context
            updated_lead = db_service.get_lead_by_phone(lead['phone_number'])
            return gemini_service.generate_stage_response('gate_question_deposit', updated_lead, conversation_history, message)
            
        else:
            # Unclear response, AI will ask for clarification while staying in same stage
            return gemini_service.generate_stage_response('gate_question_payslips', lead, conversation_history, message)
    
    def _handle_deposit_with_ai(self, lead: Dict, message: str, conversation_history: List[Dict]) -> str:
        """Handle deposit response with AI and business logic"""
        logger.info(f"Handling deposit response for lead {lead['id']} with AI")
        
        # Check if this might be a move-in date response (user skipped ahead)
        # Only if there are clear time indicators AND it's not a no/yes response
        move_days = self._extract_move_in_days(message)
        if move_days > 0 and not any(neg_word in message.lower() for neg_word in ['no', '×œ×', 'only', 'just', '×¨×§']):
            logger.info(f"Lead {lead['id']} provided move-in date without clear deposit answer - assuming yes to deposit")
            # Assume deposit is yes and process move-in date
            db_service.update_lead(lead['id'], {
                'stage': 'gate_question_move_date',
                'can_pay_deposit': True
            })
            updated_lead = db_service.get_lead_by_phone(lead['phone_number'])
            return self._handle_move_date_with_ai(updated_lead, message, conversation_history)
        
        response_type = self._analyze_yes_no_response(message, context='deposit')
        
        if response_type == 'no':
            # Failed gate question
            db_service.update_lead(lead['id'], {
                'stage': 'gate_failed',
                'can_pay_deposit': False
            })
            return gemini_service.generate_stage_response('gate_failed', lead, conversation_history, message)
            
        elif response_type == 'yes':
            # Passed second gate, move to move-in date question
            db_service.update_lead(lead['id'], {
                'stage': 'gate_question_move_date',
                'can_pay_deposit': True
            })
            updated_lead = db_service.get_lead_by_phone(lead['phone_number'])
            return gemini_service.generate_stage_response('gate_question_move_date', updated_lead, conversation_history, message)
            
        else:
            # Unclear response, stay in same stage
            return gemini_service.generate_stage_response('gate_question_deposit', lead, conversation_history, message)
    
    def _handle_move_date_with_ai(self, lead: Dict, message: str, conversation_history: List[Dict]) -> str:
        """Handle move-in date response with AI and business logic"""
        logger.info(f"Handling move-in date response for lead {lead['id']} with AI")
        
        # Extract move-in timeframe
        days_until_move = self._extract_move_in_days(message)
        max_days = current_app.config.get('MAX_MOVE_IN_DAYS', 60)
        
        if days_until_move > max_days:
            # Future move-in date
            db_service.update_lead(lead['id'], {
                'stage': 'future_fit',
                'move_in_date': message.strip()
            })
            updated_lead = db_service.get_lead_by_phone(lead['phone_number'])
            return gemini_service.generate_stage_response('future_fit', updated_lead, conversation_history, message)
            
        else:
            # Good move-in timeframe, start profile collection
            db_service.update_lead(lead['id'], {
                'stage': 'collecting_profile',
                'move_in_date': message.strip()
            })
            updated_lead = db_service.get_lead_by_phone(lead['phone_number'])
            return gemini_service.generate_stage_response('collecting_profile', updated_lead, conversation_history, message)
    
    def _handle_profile_collection_with_ai(self, lead: Dict, message: str, conversation_history: List[Dict]) -> str:
        """Handle profile collection with AI and field updates"""
        logger.info(f"Collecting profile info for lead {lead['id']} with AI")
        
        # Check what profile information is missing
        missing_info = self._get_missing_profile_info(lead)
        
        if not missing_info:
            # Profile is complete, search for properties
            return self._complete_profile_and_search_with_ai(lead, conversation_history)
        
        # Try to extract and update profile information from the message
        field_to_update = missing_info[0]
        updates = self._extract_profile_data_from_message(field_to_update, message)
        
        if updates:
            # Update the lead with extracted information
            db_service.update_lead(lead['id'], updates)
            logger.info(f"Updated lead {lead['id']} profile field '{field_to_update}': {updates}")
            
            # Refresh lead data
            updated_lead = db_service.get_lead_by_phone(lead['phone_number'])
            
            # Check if profile is now complete
            missing_after_update = self._get_missing_profile_info(updated_lead)
            if not missing_after_update:
                return self._complete_profile_and_search_with_ai(updated_lead, conversation_history)
        
        # Get updated lead data for AI context
        current_lead = db_service.get_lead_by_phone(lead['phone_number'])
        return gemini_service.generate_stage_response('collecting_profile', current_lead, conversation_history, message)
    
    def _handle_qualified_lead_with_ai(self, lead: Dict, message: str, conversation_history: List[Dict]) -> str:
        """Handle qualified lead with AI responses"""
        logger.info(f"Handling qualified lead {lead['id']} with AI")
        
        # Check if they're asking for property recommendations
        if self._is_property_request(message):
            return self._search_and_present_properties_with_ai(lead, conversation_history)
        
        # Check if they want to schedule a tour
        if self._is_scheduling_request(message):
            return self._handle_scheduling_request_with_ai(lead, message, conversation_history)
        
        # For qualified leads, let AI decide if they should see properties
        # The AI will be instructed to offer properties proactively
        ai_response = gemini_service.generate_stage_response('qualified', lead, conversation_history, message)
        
        # If AI suggests showing properties, do it
        if self._ai_suggests_showing_properties(ai_response):
            logger.info(f"AI suggested showing properties to lead {lead['id']}")
            return self._search_and_present_properties_with_ai(lead, conversation_history)
        
        return ai_response
    
    def _handle_scheduling_in_progress_with_ai(self, lead: Dict, message: str, conversation_history: List[Dict]) -> str:
        """Handle lead who is in the process of scheduling a tour"""
        logger.info(f"Handling scheduling in progress for lead {lead['id']} with AI")
        
        # Check if they're confirming they booked an appointment
        if self._is_booking_confirmation(message):
            logger.info(f"Lead {lead['id']} confirmed booking - moving to tour_scheduled")
            db_service.update_lead(lead['id'], {'stage': 'tour_scheduled'})
            updated_lead = db_service.get_lead_by_phone(lead['phone_number'])
            return self._generate_booking_confirmation_message()
        
        # Check if they need help with the Calendly link
        if self._is_calendly_help_request(message):
            logger.info(f"Lead {lead['id']} needs help with Calendly")
            calendly_link = os.getenv('CALENDLY_LINK')
            return self._generate_calendly_help_message(calendly_link)
        
        # Check if they want to go back to seeing more properties
        if self._is_property_request(message):
            logger.info(f"Lead {lead['id']} wants to see more properties before scheduling")
            db_service.update_lead(lead['id'], {'stage': 'qualified'})
            updated_lead = db_service.get_lead_by_phone(lead['phone_number'])
            return self._search_and_present_properties_with_ai(updated_lead, conversation_history)
        
        # General response for scheduling stage
        return gemini_service.generate_stage_response('scheduling_in_progress', lead, conversation_history, message)
    
    def _handle_tour_scheduled_with_ai(self, lead: Dict, message: str, conversation_history: List[Dict]) -> str:
        """Handle tour scheduled lead with AI"""
        logger.info(f"Handling tour scheduled lead {lead['id']} with AI")
        return gemini_service.generate_stage_response('tour_scheduled', lead, conversation_history, message)
    
    def _handle_ended_conversation_with_ai(self, lead: Dict, message: str, conversation_history: List[Dict]) -> str:
        """Handle ended conversations with AI"""
        stage = lead.get('stage')
        logger.info(f"Handling ended conversation for lead {lead['id']} in stage {stage} with AI")
        return gemini_service.generate_stage_response(stage, lead, conversation_history, message)
    
    def _handle_unknown_stage_with_ai(self, lead: Dict, message: str, conversation_history: List[Dict]) -> str:
        """Handle unknown stage with AI"""
        logger.warning(f"Unknown stage for lead {lead['id']}: {lead.get('stage')}")
        # Default to qualified stage for unknown stages
        return gemini_service.generate_stage_response('qualified', lead, conversation_history, message)
    
    def _complete_profile_and_search_with_ai(self, lead: Dict, conversation_history: List[Dict]) -> str:
        """Complete profile collection and search for properties with AI"""
        logger.info(f"Profile complete for lead {lead['id']}, searching properties with AI")
        
        # Update stage to qualified
        db_service.update_lead(lead['id'], {'stage': 'qualified'})
        
        # Search for matching properties
        units = self._search_matching_properties(lead)
        
        if units:
            # Found matching properties, generate AI recommendation and send images
            ai_response = gemini_service.generate_property_recommendation(lead, units)
            
            # Send property images after AI text response
            try:
                from app.services.messaging_service import messaging_service
                messaging_service.send_property_images(lead['id'], units)
                logger.info(f"Property images sent to lead {lead['id']}")
            except Exception as e:
                logger.error(f"Failed to send property images to lead {lead['id']}: {e}")
            
            return ai_response
        else:
            # No matching properties, generate AI response for alternatives
            return gemini_service.generate_no_properties_response(lead, conversation_history)
    
    def _search_and_present_properties_with_ai(self, lead: Dict, conversation_history: List[Dict]) -> str:
        """Search and present properties with AI"""
        logger.info(f"Searching properties for qualified lead {lead['id']} with AI")
        
        units = self._search_matching_properties(lead)
        
        if units:
            # Generate AI recommendation and send images
            ai_response = gemini_service.generate_property_recommendation(lead, units)
            
            # Send property images after AI text response
            try:
                from app.services.messaging_service import messaging_service
                messaging_service.send_property_images(lead['id'], units)
                logger.info(f"Property images sent to qualified lead {lead['id']}")
            except Exception as e:
                logger.error(f"Failed to send property images to qualified lead {lead['id']}: {e}")
            
            return ai_response
        else:
            return gemini_service.generate_no_properties_response(lead, conversation_history)
    
    def _handle_scheduling_request_with_ai(self, lead: Dict, message: str, conversation_history: List[Dict]) -> str:
        """Handle scheduling request with AI"""
        logger.info(f"Handling scheduling request for lead {lead['id']} with AI")
        
        # Get Calendly link from environment with fallback
        calendly_link = os.getenv('CALENDLY_LINK')
        
        if not calendly_link:
            logger.warning("No CALENDLY_LINK configured in environment, using manual scheduling")
            # Update stage to scheduling in progress
            db_service.update_lead(lead['id'], {'stage': 'scheduling_in_progress'})
            return self._generate_manual_scheduling_message()
        
        # Update stage to scheduling in progress
        db_service.update_lead(lead['id'], {'stage': 'scheduling_in_progress'})
        
        # Generate scheduling message with Calendly link
        return self._generate_calendly_message(calendly_link)
    
    def _generate_calendly_message(self, calendly_link: str) -> str:
        """Generate scheduling message with Calendly link and confirmation instructions"""
        return f"""ğŸ‰ ××¢×•×œ×”! ×‘×•××• × ×ª×× ×¤×’×™×©×” ×œ×¦×¤×™×™×” ×‘×“×™×¨×•×ª!

ğŸ‘‡ ×œ×—×¥ ×¢×œ ×”×§×™×©×•×¨ ×”×–×” ×œ×‘×—×™×¨×ª ×”×ª××¨×™×š ×•×”×©×¢×” ×©× ×•×—×™× ×œ×š:

{calendly_link}

ğŸ“ ××—×¨×™ ×©×ª×–××™×Ÿ ×¤×’×™×©×” ×‘×§×œ× ×“×œ×™, ×× × ×—×–×•×¨ ×œ×›××Ÿ ×•××©×¨ ×œ×™ ×©×§×‘×¢×ª - ×›×“×™ ×©××•×›×œ ×œ×”×›×™×Ÿ ××ª ×›×œ ×”×¤×¨×˜×™× ×¢×‘×•×¨×š!

â° ×”×¤×’×™×©×” ×ª×§×— ×‘×¢×¨×š 30-45 ×“×§×•×ª, ×•×× ×™ ××œ×•×•×” ××•×ª×š ×œ×¨××•×ª ××ª ×”×“×™×¨×•×ª ×©×”×›×™ ××ª××™××•×ª ×œ×ª×§×¦×™×‘ ×•×œ×“×¨×™×©×•×ª ×©×œ×š.

ğŸ’¡ ×˜×™×¤: ××•××œ×¥ ×œ×§×‘×•×¢ ×œ×¤×—×•×ª ×™×•× ××¨××© ×›×“×™ ×©××•×›×œ ×œ×”×›×™×Ÿ ×¢×‘×•×¨×š ××ª ×”×“×™×¨×•×ª ×”×˜×•×‘×•×ª ×‘×™×•×ª×¨!

×™×© ×œ×š ×©××œ×•×ª × ×•×¡×¤×•×ª? ×× ×™ ×›××Ÿ ×œ×¢×–×•×¨! ğŸ˜Š"""
    
    def _generate_manual_scheduling_message(self) -> str:
        """Generate manual scheduling message when Calendly is not available"""
        return """ğŸ‰ ××¢×•×œ×”! ×‘×•××• × ×ª×× ×¤×’×™×©×” ×œ×¦×¤×™×™×” ×‘×“×™×¨×•×ª!

ğŸ“… ×× ×™ ××ª×× ××™×ª×š ×¤×’×™×©×” ×‘××•×¤×Ÿ ××™×©×™.

â° ×× × ×¡×¤×¨ ×œ×™ ××ª×™ × ×•×— ×œ×š:
â€¢ ××™×–×” ×™×•× ××”×©×‘×•×¢ ×”×‘×?
â€¢ ××™×–×” ×©×¢×” ××•×¢×“×¤×ª ×¢×œ×™×š? (×‘×•×§×¨/×¦×”×¨×™×™×/××—×¨ ×”×¦×”×¨×™×™×)

ğŸ“ ×”×¤×’×™×©×” ×ª×§×— ×‘×¢×¨×š 30-45 ×“×§×•×ª, ×•×× ×™ ××œ×•×•×” ××•×ª×š ×œ×¨××•×ª ××ª ×”×“×™×¨×•×ª ×©×”×›×™ ××ª××™××•×ª ×œ×ª×§×¦×™×‘ ×•×œ×“×¨×™×©×•×ª ×©×œ×š.

ğŸ’¡ ×× ×™ ××›×™×Ÿ ×¢×‘×•×¨×š ××¨××© ××ª ×”×“×™×¨×•×ª ×”×˜×•×‘×•×ª ×‘×™×•×ª×¨!

×›×ª×•×‘ ×œ×™ ××ª ×”×–××Ÿ ×©× ×•×— ×œ×š ×•×× ×™ ××¡×“×¨ ×”×›×œ! ğŸ˜Š"""
    
    def _is_booking_confirmation(self, message: str) -> bool:
        """Check if message is confirming that they booked an appointment"""
        message_lower = message.lower().strip()
        
        confirmation_phrases = [
            '×§×‘×¢×ª×™', '×”×–×× ×ª×™', '×ª×™×××ª×™', '×¨×©××ª×™',
            'booked', 'scheduled', 'confirmed', 'set',
            '×§×™×‘×œ×ª×™ ××™×©×•×¨', '× ×§×‘×¢', '×–×•××Ÿ', '×¢×©×™×ª×™', '×¡×™×“×¨×ª×™',
            'done', 'finished', 'completed'
        ]
        
        for phrase in confirmation_phrases:
            if phrase in message_lower:
                return True
        
        return False
    
    def _is_calendly_help_request(self, message: str) -> bool:
        """Check if they need help with the Calendly booking process"""
        message_lower = message.lower().strip()
        
        help_phrases = [
            '×œ× ×¢×•×‘×“', '×‘×¢×™×”', '×¢×–×¨×”', '×œ× ××¦×œ×™×—', '×œ× ×™×›×•×œ',
            'not working', 'help', 'problem', 'issue', 'error',
            '×›×©×œ', '×ª×§×œ×”', '×œ× ×¤×•×ª×—', '×œ× × ×˜×¢×Ÿ',
            'cant', "can't", 'cannot', 'broken', 'stuck'
        ]
        
        for phrase in help_phrases:
            if phrase in message_lower:
                return True
        
        return False
    
    def _generate_booking_confirmation_message(self) -> str:
        """Generate message confirming that appointment was booked"""
        return """ğŸ‰ ××¢×•×œ×”! ×§×™×‘×œ×ª×™ ××ª ×”××™×©×•×¨ ×©×§×‘×¢×ª ×¤×’×™×©×”!

âœ… ×× ×™ ××›×™×Ÿ ×¢×‘×•×¨×š ××ª ×›×œ ×”×¤×¨×˜×™× ×œ×¤×’×™×©×” ×•××©×œ×— ×œ×š ×ª×–×›×•×¨×•×ª ×œ×¤× ×™ ×”××•×¢×“.

ğŸ“‹ ×‘××”×œ×š ×”×¤×’×™×©×” × ×¨××” ×‘×™×—×“:
â€¢ ××ª ×”×“×™×¨×•×ª ×©×”×›×™ ××ª××™××•×ª ×œ×ª×§×¦×™×‘ ×©×œ×š
â€¢ × ×‘×“×•×§ ××ª ×”××™×§×•× ×•×”×¡×‘×™×‘×”
â€¢ × ×¢×‘×•×¨ ×¢×œ ×›×œ ×”×¤×¨×˜×™× ×”×—×©×•×‘×™×

ğŸ“ ×× ×™×© ×œ×š ×©××œ×•×ª × ×•×¡×¤×•×ª ×œ×¤× ×™ ×”×¤×’×™×©×” - ×× ×™ ×›××Ÿ!

××—×›×” ×œ×¤×’×•×© ××•×ª×š! ğŸ˜Š"""
    
    def _generate_calendly_help_message(self, calendly_link: str) -> str:
        """Generate help message when user has issues with Calendly"""
        return f"""ğŸ˜” ××¦×˜×¢×¨ ×©×™×© ×‘×¢×™×”! ×‘×•××• × × ×¡×” ×©×•×‘:

ğŸ”§ ×“×‘×¨×™× ×œ×‘×“×•×§:
â€¢ ×•×“× ×©×”×§×™×©×•×¨ × ×¤×ª×— ×‘×“×¤×“×¤×Ÿ
â€¢ × ×¡×” ×œ×¨×¢× ×Ÿ ××ª ×”×“×£
â€¢ ×× ××ª×” ×‘××•×‘×™×™×œ - × ×¡×” ×œ×¤×ª×•×— ×‘×“×¤×“×¤×Ÿ ×•×œ× ×‘××¤×œ×™×§×¦×™×”

ğŸ‘‡ ×”× ×” ×©×•×‘ ×”×§×™×©×•×¨ ×œ×ª×™××•×:
{calendly_link}

ğŸ“ ×× ×–×” ×¢×“×™×™×Ÿ ×œ× ×¢×•×‘×“, ××ª×” ×™×›×•×œ:
â€¢ ×œ×©×œ×•×— ×œ×™ ×”×•×“×¢×” ×¢× ×”×ª××¨×™×›×™× ×©× ×•×—×™× ×œ×š
â€¢ ××• ×œ×›×ª×•×‘ ×œ×™ ××™×–×” ×™×•× ×•×©×¢×” ××ª××™××™× ×œ×š

×× ×™ ××“××’ ×©× ××¦× ×¤×ª×¨×•×Ÿ! ğŸ˜Š"""
    
    # Helper methods for business logic
    
    def _is_greeting(self, message: str) -> bool:
        """Check if message is a greeting"""
        message_lower = message.lower()
        for pattern in self.greeting_patterns:
            if re.search(pattern, message_lower, re.IGNORECASE):
                return True
        return False
    
    def _analyze_yes_no_response(self, message: str, context: str = None) -> str:
        """Enhanced analysis of yes/no responses with context awareness"""
        message_lower = message.lower().strip()
        
        # Handle common conversational patterns
        positive_phrases = [
            'ok', 'okay', '××•×§×™×™', '×‘×¡×“×¨', '×˜×•×‘', '× ×”×“×¨', '××¦×•×™×Ÿ', '×‘×˜×—', '×•×“××™',
            '×›×Ÿ', 'yes', '×™×©', '××›×Ÿ', '×‘×•×•×“××™', '×›××•×‘×Ÿ', '× ×›×•×Ÿ', '×™×¤×”', '×™×•×¤×™',
            '×× ×™ ×™×›×•×œ', '×™×© ×œ×™', 'i can', 'i have', 'can do', '××•×›×œ', '××¡×•×’×œ',
            'ill pay', '×× ×™ ××©×œ×', '××©×œ×', '××©×œ×', '××¤×©×¨ ×œ×™', '×™×›×•×œ ×œ×©×œ×',
            '× ×ª×Ÿ', '××ª×Ÿ', 'give', 'provide', '××¡×¤×§'
        ]
        
        negative_phrases = [
            '×œ× ×™×›×•×œ', '××™×Ÿ ××¤×©×¨×•×ª', '×œ× × ×™×ª×Ÿ', 'cant', "can't", 'cannot',
            'impossible', '× ××•×š', '×§×©×”', '×‘×¢×™×”', '×—×¡×¨', '××™×Ÿ ×‘××¤×©×¨×•×ª×™',
            '×œ×', 'no', '××™×Ÿ', '××™× × ×™', '××™× ×™', '×‘×œ×™', '××™×Ÿ ×œ×™', '×× ×™ ×œ×'
        ]
        
        # Context-aware analysis for deposit-related messages
        if context == 'deposit' or any(word in message_lower for word in ['×¢×¨×‘×•×ª', 'deposit', 'guarantee', 'pay', '×©×œ×']):
            # Handle deposit rejection patterns FIRST (more specific)
            if any(phrase in message_lower for phrase in [
                'cant pay', '×œ× ×™×›×•×œ ×œ×©×œ×', '××™×Ÿ ×œ×™ ×¢×¨×‘×•×ª', 'no deposit', '××™×Ÿ ×¢×¨×‘×•×ª',
                '×œ× ××•×›×œ ×œ×©×œ×', '×—×¡×¨ ×œ×™', '××™×Ÿ ×‘××¤×©×¨×•×ª×™', "can't pay", 'cannot pay'
            ]):
                return 'no'
            
            # Then handle deposit acceptance patterns
            if any(phrase in message_lower for phrase in [
                'ok ill pay', 'ill pay it', '×× ×™ ××©×œ×', '××©×œ× ××ª ×–×”', '××ª×Ÿ ×¢×¨×‘×•×ª',
                '×™×© ×œ×™ ×¢×¨×‘×•×ª', 'can pay', '×™×›×•×œ ×œ×©×œ×', '×‘×¡×“×¨ ××©×œ×', '××•×§×™×™ ××©×œ×'
            ]):
                return 'yes'
        
        # First check for clear negative patterns
        clear_negative_patterns = [
            '×œ× ×™×›×•×œ ×œ×©×œ×', '××™×Ÿ ××¤×©×¨×•×ª', '×œ× × ×™×ª×Ÿ', 'cant pay', "can't pay", 'cannot pay',
            'impossible', '××™×Ÿ ×‘××¤×©×¨×•×ª×™'
        ]
        
        for pattern in clear_negative_patterns:
            if pattern in message_lower:
                return 'no'
        
        # Then check for positive responses
        for phrase in positive_phrases:
            if phrase in message_lower:
                return 'yes'
        
        # Finally check for general negative words (but only if not already caught)
        simple_negatives = ['×œ×', 'no', '××™×Ÿ', '××™× × ×™', '××™× ×™', '×‘×œ×™', '××™×Ÿ ×œ×™', '×× ×™ ×œ×']
        for phrase in simple_negatives:
            if phrase in message_lower:
                return 'no'
        
        # Check for numeric/specific responses that might indicate agreement
        if context == 'deposit' and re.search(r'\d+.*×—×•×“×©|month.*\d+', message_lower):
            return 'yes'  # Mentioning specific months usually means agreement
        
        return 'unclear'
    
    def _extract_move_in_days(self, message: str) -> int:
        """Extract move-in timeframe in days using AI"""
        try:
            # Use AI to intelligently parse any move-in date expression
            prompt = f"""
Analyze this message and extract the move-in timeframe in days.

Message: "{message}"

Convert any time expression to the equivalent number of days from today.

Examples:
- "tomorrow" = 1
- "next week" = 7
- "in 2 weeks" = 14
- "in a month" = 30
- "3 months" = 90
- "half a year" = 180
- "××™×“" = 1
- "×©×‘×•×¢ ×”×‘×" = 7
- "×—×•×“×©" = 30
- "×‘×¢×•×“ 20 ×™×•×" = 20
- "20 days" = 20
- "in 45 days" = 45

If no clear timeframe is mentioned, return 0.
If the timeframe is vague like "soon" or "when possible", estimate 7 days.

Response format: Only return the number of days as an integer, nothing else.
"""
            
            response = gemini_service.generate_raw_response(prompt)
            
            # Extract number from AI response
            numbers = re.findall(r'\d+', response.strip())
            if numbers:
                return int(numbers[0])
            
            return 0  # Fallback if AI doesn't return a number
            
        except Exception as e:
            logger.error(f"Error extracting move-in days with AI: {e}")
            # Simple fallback: look for any number in the message
            numbers = re.findall(r'\d+', message)
            if numbers:
                return int(numbers[0])
            return 30  # Default fallback
    
    def _get_missing_profile_info(self, lead: Dict) -> List[str]:
        """Get list of missing profile information in order of collection"""
        missing = []
        
        # Field mapping from database fields to collection field names
        field_mapping = {
            'rooms': 'rooms',
            'budget': 'budget', 
            'has_parking': 'parking',
            'preferred_area': 'area'
        }
        
        collection_order = ['rooms', 'budget', 'parking', 'area']
        
        for field in collection_order:
            db_field = field if field in ['rooms', 'budget'] else {'parking': 'has_parking', 'area': 'preferred_area'}[field]
            
            if lead.get(db_field) is None or (field == 'area' and not lead.get('preferred_area')):
                missing.append(field)
        
        return missing
    
    def _extract_profile_data_from_message(self, field: str, message: str) -> Dict:
        """Extract profile data from message based on field type"""
        updates = {}
        
        if field == 'rooms':
            rooms = self._extract_number_from_message(message)
            if rooms and 1 <= rooms <= 10:
                updates['rooms'] = rooms
                
        elif field == 'budget':
            budget = self._extract_budget_from_message(message)
            if budget and budget > 0:
                updates['budget'] = budget
                
        elif field == 'parking':
            parking_response = self._analyze_yes_no_response(message, context='parking')
            if parking_response in ['yes', 'no']:
                updates['has_parking'] = (parking_response == 'yes')
                
        elif field == 'area':
            # Any non-empty text is valid for area preference
            area = message.strip()
            if area and len(area) > 1:
                updates['preferred_area'] = area
        
        return updates
    
    def _extract_number_from_message(self, message: str) -> Optional[int]:
        """Extract number from message"""
        try:
            # Hebrew number words
            hebrew_numbers = {
                '××—×“': 1, '×©× ×™': 2, '×©×œ×•×©': 3, '××¨×‘×¢': 4, '×—××©': 5,
                '×©×©': 6, '×©×‘×¢': 7, '×©××•× ×”': 8, '×ª×©×¢': 9, '×¢×©×¨': 10,
                '××—×ª': 1, '×©×ª×™×™×': 2, '×©×œ×•×©×”': 3, '××¨×‘×¢×”': 4, '×—××™×©×”': 5
            }
            
            message_lower = message.lower()
            
            # Check for Hebrew number words
            for word, num in hebrew_numbers.items():
                if word in message_lower:
                    return num
            
            # Extract digits
            numbers = re.findall(r'\d+', message)
            if numbers:
                return int(numbers[0])
            
            return None
        except:
            return None
    
    def _extract_budget_from_message(self, message: str) -> Optional[float]:
        """Extract budget from message"""
        try:
            # Remove commas and extract numbers
            cleaned = re.sub(r'[,\s]', '', message)
            numbers = re.findall(r'\d+', cleaned)
            
            if numbers:
                budget = float(numbers[0])
                
                # Handle different units
                message_lower = message.lower()
                if 'k' in message_lower or '××œ×£' in message_lower:
                    budget *= 1000
                elif budget < 100:  # Assume thousands if very small number
                    budget *= 1000
                
                # Reasonable budget range (1000-50000 NIS)
                if 1000 <= budget <= 50000:
                    return budget
            
            return None
        except:
            return None
    
    def _search_matching_properties(self, lead: Dict) -> List[Dict]:
        """Search for properties matching lead criteria"""
        try:
            search_criteria = {}
            
            if lead.get('rooms'):
                search_criteria['min_rooms'] = lead['rooms']
                search_criteria['max_rooms'] = lead['rooms']
            
            if lead.get('budget'):
                search_criteria['max_price'] = float(lead['budget'])
            
            if lead.get('has_parking') is not None:
                search_criteria['parking'] = lead['has_parking']
            
            logger.info(f"Searching properties with criteria: {search_criteria}")
            
            units = db_service.get_available_units(search_criteria)
            logger.info(f"Found {len(units)} matching units for lead {lead['id']}")
            
            return units
            
        except Exception as e:
            logger.error(f"Error searching properties for lead {lead['id']}: {e}")
            return []
    
    def _is_property_request(self, message: str) -> bool:
        """Check if message is requesting to see properties"""
        message_lower = message.lower()
        property_keywords = [
            '×“×™×¨×•×ª', '× ×›×¡×™×', '××¤×©×¨×•×™×•×ª', '××” ×™×©', '×ª×¦×™×’', '×ª×¨××”',
            '×‘×•× × ×¨××”', '××¦×', '×—×¤×©', '×™×© ×œ×›×', '×ª××•× ×•×ª', '×¤×¨×˜×™×'
        ]
        
        for keyword in property_keywords:
            if keyword in message_lower:
                return True
        return False
    
    
    def _ai_suggests_showing_properties(self, ai_response: str) -> bool:
        """Check if AI response suggests showing properties to the user"""
        response_lower = ai_response.lower()
        
        # Look for key phrases that indicate AI wants to show properties
        property_suggestion_phrases = [
            '×‘×•× ××¨××” ×œ×š', '×‘×•××• × ×¨××”', '××¦×™×’ ×œ×š', '×ª×¨××” ×œ×š',
            '×™×© ×œ×™', '××¦××ª×™', '×××¦×', 
            'let me show you', 'i will show', 'i found', 'let me find'
        ]
        
        for phrase in property_suggestion_phrases:
            if phrase in response_lower:
                return True
        
        return False
    
    def _is_scheduling_request(self, message: str) -> bool:
        """Check if message is requesting to schedule a tour"""
        message_lower = message.lower()
        scheduling_keywords = [
            # Hebrew
            '×¡×™×•×¨', '×¤×’×™×©×”', '×‘×™×§×•×¨', '×œ×¨××•×ª', '×œ×‘×•×', '×œ×ª××', '×–××Ÿ',
            '××ª×™', '××¤×©×¨', '× ×•×— ×œ×š', '×ª×™××•×', '×§×‘×™×¢×”',
            # English
            'schedule', 'meeting', 'appointment', 'visit', 'tour', 'see',
            'meet', 'when', 'time', 'book', 'arrange'
        ]
        
        for keyword in scheduling_keywords:
            if keyword in message_lower:
                return True
        return False


# Global lead service instance
lead_service = LeadService()